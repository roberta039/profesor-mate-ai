import streamlit as st
import google.generativeai as genai
from PIL import Image

# 1. Configurare PaginÄƒ
st.set_page_config(page_title="Profesor Universal (2.5 Flash)", page_icon="ğŸ“")
st.title("ğŸ“ Profesor Universal")

# 2. Configurare API Key
if "GOOGLE_API_KEY" in st.secrets:
    api_key = st.secrets["GOOGLE_API_KEY"]
else:
    api_key = st.sidebar.text_input("Introdu Google API Key:", type="password")

if not api_key:
    st.info("Introdu cheia Google API pentru a Ã®ncepe.")
    st.stop()

try:
    genai.configure(api_key=api_key)
except Exception as e:
    st.error(f"Eroare la configurare cheie: {e}")
    st.stop()

# --- ZONA DE LISTARE MODEL ---
st.sidebar.header("âš™ï¸ Alege Modelul")

@st.cache_data
def get_available_models():
    # AICI AM MODIFICAT:
    # Am pus "gemini-2.5-flash" primul. Acesta va fi Default.
    priority_list = [
        "models/gemini-2.5-flash", 
        "models/gemini-2.0-flash-exp", 
        "models/gemini-1.5-flash", 
        "models/gemini-1.5-pro"
    ]
    
    found_list = []
    
    # Lista neagrÄƒ pentru modele care nu merg (TTS, Audio, etc)
    blacklist = ["tts", "audio", "embedding", "aqa", "speaker", "vision-only"]
    
    try:
        for m in genai.list_models():
            if 'generateContent' in m.supported_generation_methods:
                name = m.name.lower()
                if "gemini" in name:
                    # AplicÄƒm filtrul ca sÄƒ nu aparÄƒ erori
                    if not any(bad_word in name for bad_word in blacklist):
                        found_list.append(m.name)
    except:
        pass
    
    found_list.sort(reverse=True)
    
    # CombinÄƒm listele. Deoarece priority_list e prima, elementul 0 (2.5 flash) va fi primul.
    final_list = list(dict.fromkeys(priority_list + found_list))
    
    return final_list

available_models = get_available_models()

# Selectbox ia automat index=0, adicÄƒ primul din listÄƒ (2.5 Flash)
selected_model_name = st.sidebar.selectbox("Model:", available_models, index=0)

# VerificÄƒm schimbarea modelului pentru refresh la chat
if "last_model" not in st.session_state:
    st.session_state["last_model"] = selected_model_name

if st.session_state["last_model"] != selected_model_name:
    st.session_state["messages"] = [{"role": "assistant", "content": f"Salut! Am trecut pe {selected_model_name}. Cu ce te ajut?"}]
    st.session_state["last_model"] = selected_model_name
    st.rerun()

# --- CONFIGURARE PROFESOR ---
try:
        model = genai.GenerativeModel(
        selected_model_name,
        system_instruction="""EÈ™ti un profesor universal (Mate, FizicÄƒ, Chimie) rÄƒbdÄƒtor È™i empatic.
        
        REGULÄ‚ STRICTÄ‚: PredÄƒ exact ca la È™coalÄƒ (nivel Gimnaziu/Liceu). 
        NU confunda elevul cu detalii despre "aproximÄƒri" sau "lumea realÄƒ" decÃ¢t dacÄƒ problema o cere specific.

        Ghid de comportament:
        1. MATEMATICÄ‚: LucreazÄƒ cu valori exacte sau standard. 
           - DacÄƒ rezultatul e $\sqrt{2}$, lasÄƒ-l $\sqrt{2}$. Nu spune "care este aproximativ 1.41".
           - Nu menÈ›iona cÄƒ $\pi$ e infinit; foloseÈ™te valorile din manual fÄƒrÄƒ comentarii suplimentare.
           - DacÄƒ rezultatul e rad(2), lasÄƒ-l rad(2). Nu Ã®l calcula aproximativ.
        2. FIZICÄ‚/CHIMIE: Presupune automat "condiÈ›ii ideale".
           - Nu menÈ›iona frecarea cu aerul, pierderile de cÄƒldurÄƒ sau imperfecÈ›iunile aparatelor de mÄƒsurÄƒ.
           - TrateazÄƒ problema exact aÈ™a cum apare Ã®n culegere, Ã®ntr-un univers matematic perfect.
        3. Stilul de predare: ExplicÄƒ simplu, cald È™i prietenos. EvitÄƒ limbajul academic rigid ("limbajul de lemn").
        4. Analogii: FoloseÈ™te comparaÈ›ii din viaÈ›a realÄƒ pentru a explica concepte abstracte (ex: "Voltajul e ca presiunea apei pe o È›eavÄƒ").
        5. Teorie: CÃ¢nd eÈ™ti Ã®ntrebat de teorie, defineÈ™te conceptul, apoi dÄƒ un exemplu concret, apoi explicÄƒ la ce ne ajutÄƒ Ã®n viaÈ›a realÄƒ.
        6. Rezolvare probleme: Nu da doar rezultatul. ExplicÄƒ paÈ™ii logici ("Facem asta pentru cÄƒ...", "Ãn momentul Ã®n care.....).
        7. Formule: FoloseÈ™te LaTeX ($...$) pentru claritate, dar explicÄƒ ce Ã®nseamnÄƒ fiecare literÄƒ din formulÄƒ.
        """
    )
except Exception as e:
    st.error(f"Eroare la iniÈ›ializarea modelului: {e}")

# 3. InterfaÈ›a de Upload
st.sidebar.header("ğŸ“ Materiale")
uploaded_file = st.sidebar.file_uploader("ÃncarcÄƒ o pozÄƒ", type=["jpg", "jpeg", "png"])

img = None
if uploaded_file:
    img = Image.open(uploaded_file)
    st.sidebar.image(img, caption="Imagine Ã®ncÄƒrcatÄƒ", use_container_width=True)

# 4. Chat History
if "messages" not in st.session_state:
    st.session_state["messages"] = [{"role": "assistant", "content": f"Salut! Folosesc {selected_model_name}. Cu ce te ajut?"}]

for msg in st.session_state.messages:
    st.chat_message(msg["role"]).write(msg["content"])

# 5. Input
if user_input := st.chat_input("Scrie problema..."):
    st.session_state.messages.append({"role": "user", "content": user_input})
    st.chat_message("user").write(user_input)

    inputs = [user_input]
    if img:
        inputs.append(img)

    with st.chat_message("assistant"):
        with st.spinner("Rezolv..."):
            try:
                response = model.generate_content(inputs)
                st.write(response.text)
                st.session_state.messages.append({"role": "assistant", "content": response.text})
            except Exception as e:
                err_msg = str(e).lower()
                st.error(f"Eroare: {e}")
                
                if "image input modality is not enabled" in err_msg:
                    st.warning("âš ï¸ Modelul selectat nu suportÄƒ imagini. Alege altul.")
                elif "quota" in err_msg or "429" in err_msg:
                    st.warning("âš ï¸ Limita atinsÄƒ. ÃncearcÄƒ 'gemini-1.5-flash'.")
